{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b8d2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Accuracy: 0.7799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       215\n",
      "           1       0.74      0.80      0.77       181\n",
      "           2       0.77      0.71      0.74       170\n",
      "           3       0.77      0.76      0.77       170\n",
      "\n",
      "    accuracy                           0.78       736\n",
      "   macro avg       0.78      0.78      0.78       736\n",
      "weighted avg       0.78      0.78      0.78       736\n",
      "\n",
      "LinearSVC Accuracy: 0.7894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       215\n",
      "           1       0.75      0.83      0.79       181\n",
      "           2       0.77      0.76      0.76       170\n",
      "           3       0.80      0.75      0.78       170\n",
      "\n",
      "    accuracy                           0.79       736\n",
      "   macro avg       0.79      0.79      0.79       736\n",
      "weighted avg       0.79      0.79      0.79       736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/horiuchiminori/opt/anaconda3/envs/py311/lib/python3.12/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Accuracy: 0.7283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76       215\n",
      "           1       0.68      0.75      0.72       181\n",
      "           2       0.76      0.68      0.72       170\n",
      "           3       0.72      0.71      0.71       170\n",
      "\n",
      "    accuracy                           0.73       736\n",
      "   macro avg       0.73      0.73      0.73       736\n",
      "weighted avg       0.73      0.73      0.73       736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"/Users/horiuchiminori/Desktop/研究/datasets/日本語4クラス/4emos_jp_4000.csv\")\n",
    "text_col = 'text' if 'text' in df.columns else df.select_dtypes(include=[object]).columns[0]\n",
    "label_col = 'label' if 'label' in df.columns else [c for c in df.columns if c!=text_col][0]\n",
    "\n",
    "X = df[text_col].astype(str).values\n",
    "y = df[label_col].astype(str).values\n",
    "\n",
    "# 日本語判定（簡易）\n",
    "def is_japanese_text(samples, threshold=0.3):\n",
    "    count = 0\n",
    "    total = min(len(samples), 200)\n",
    "    for s in samples[:total]:\n",
    "        if any('\\u3040' <= ch <= '\\u30ff' or '\\u4e00' <= ch <= '\\u9fff' for ch in s):\n",
    "            count += 1\n",
    "    return (count / total) >= threshold\n",
    "\n",
    "is_jp = is_japanese_text(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "if is_jp:\n",
    "    vect = TfidfVectorizer(analyzer='char_wb', ngram_range=(2,4), max_features=2000)\n",
    "else:\n",
    "    vect = TfidfVectorizer(analyzer='word', ngram_range=(1,2), max_features=2000)\n",
    "\n",
    "models = {\n",
    "    \"LogReg\": Pipeline([('tfidf', vect), ('clf', LogisticRegression(max_iter=1000))]),\n",
    "    \"LinearSVC\": Pipeline([('tfidf', vect), ('clf', LinearSVC())]),\n",
    "    \"RandomForest\": Pipeline([('tfidf', vect), ('clf', RandomForestClassifier(n_jobs=1, n_estimators=100))])\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    rpt = classification_report(y_test, y_pred, zero_division=0)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=np.unique(y))\n",
    "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
    "    print(rpt)\n",
    "    results[name] = {'model': model, 'accuracy': acc, 'report': rpt, 'cm': cm}\n",
    "\n",
    "best_name = max(results.keys(), key=lambda k: results[k]['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab1445c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      text  label\n",
      "0  顧客から高い評価をもらえて誇らしい気持ちです！      0\n",
      "1      上司が急に出張を取りやめて驚きました。      3\n",
      "2       納得できない決定に苛立ちを感じます！      1\n",
      "3       会議中に新しい提案が出て驚きました。      3\n",
      "4        言い訳ばかりで誠実さを感じません！      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/horiuchiminori/opt/anaconda3/envs/py311/lib/python3.12/site-packages/spacy/util.py:922: UserWarning: [W095] Model 'ja_core_news_sm' (3.7.0) was trained with spaCy v3.7.0 and may not be 100% compatible with the current version (3.8.7). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 分類結果 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.07      1.00      0.13         1\n",
      "\n",
      "    accuracy                           0.06        16\n",
      "   macro avg       0.02      0.25      0.03        16\n",
      "weighted avg       0.00      0.06      0.01        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/horiuchiminori/opt/anaconda3/envs/py311/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/horiuchiminori/opt/anaconda3/envs/py311/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/horiuchiminori/opt/anaconda3/envs/py311/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# ===== ライブラリのインポート =====\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "# ===== データの読み込み =====\n",
    "df = pd.read_csv(\"/Users/horiuchiminori/Desktop/研究/datasets/日本語4クラス/combined_unique_texts.csv\")\n",
    "print(df.head())\n",
    "\n",
    "# ===== 前処理 =====\n",
    "# 日本語モデルをロード（例：ja_core_news_sm）\n",
    "nlp = spacy.load(\"ja_core_news_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[0-9０-９]+', '0', text)  # 数字を0に統一\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.pos_ != \"PUNCT\"]\n",
    "    return tokens\n",
    "\n",
    "# トークン化\n",
    "df[\"tokens\"] = df[\"text\"].astype(str).apply(preprocess)\n",
    "\n",
    "# ===== Word2Vec モデル学習 =====\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=df[\"tokens\"],\n",
    "    vector_size=100,  # ベクトル次元\n",
    "    window=5,         # 文脈ウィンドウサイズ\n",
    "    min_count=1,      # 出現頻度の閾値\n",
    "    sg=1,             # Skip-gram（0ならCBOW）\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "# ===== 各文のベクトルを作成 =====\n",
    "def sentence_vector(tokens):\n",
    "    vecs = []\n",
    "    for w in tokens:\n",
    "        if w in w2v_model.wv:\n",
    "            vecs.append(w2v_model.wv[w])\n",
    "    if len(vecs) == 0:\n",
    "        return np.zeros(w2v_model.vector_size)\n",
    "    else:\n",
    "        return np.mean(vecs, axis=0)\n",
    "\n",
    "df[\"vector\"] = df[\"tokens\"].apply(sentence_vector)\n",
    "X = np.vstack(df[\"vector\"].values)\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# ===== 学習・評価 =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"=== 分類結果 ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
