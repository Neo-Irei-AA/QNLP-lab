{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c39953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from lambeq.backend.drawing import draw\n",
    "from lambeq.backend.grammar import Cup, Id, Ty, Word\n",
    "from lambeq import AtomicType, IQPAnsatz, NumpyModel, BinaryCrossEntropyLoss, CrossEntropyLoss, QuantumTrainer, SPSAOptimizer, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# 型の定義\n",
    "n, s = Ty('n'), Ty('s')\n",
    "\n",
    "# 言語モデルのロード\n",
    "#nlp = spacy.load(\"ja_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5020d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここからラベル付け\n",
    "#df = pd.read_csv(\"/Users/horiuchiminori/Desktop/研究/datasets/travel_dataset/travel_dataset_large.csv\")\n",
    "\n",
    "# ユニークなクラスを確認\n",
    "#classes = df[\"label\"].unique()\n",
    "\n",
    "# One-vs-Rest用のラベルを作成\n",
    "#for cls in classes:\n",
    "    #column_name = f\"class_{cls}_vs_rest\"\n",
    "    #df[column_name] = (df[\"label\"] == cls).astype(int)\n",
    "\n",
    "# 保存（必要に応じて）\n",
    "#df.to_csv(\"travel_dataset_large_ovr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5302f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/horiuchiminori/Desktop/研究/datasets/travel_dataset/three_class_dataset_ovr_with_label.csv\")\n",
    "# /Users/horiuchiminori/Desktop/研究/datasets/travel_dataset/three_class_dataset_ovr_with_label.csv\n",
    "# /Users/horiuchiminori/Desktop/研究/datasets/nlp_multiclass_ovr_dataset_cleaned.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a960d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 型の割り当て\n",
    "def assign_types(doc):\n",
    "    pregroup_types = {}\n",
    "    doc = nlp(sentence)\n",
    "    # トークン化\n",
    "    tokens = [token.text for token in doc]\n",
    "\n",
    "    # ROOTとそれに繋がる名詞（主語・目的語）のみ、dep関係をリストに格納\n",
    "    dependencies = []\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'ROOT':\n",
    "            pregroup_types[token.text] = s\n",
    "            dependencies.append((token.text, token.head.text))\n",
    "        elif token.pos_ in ['NOUN', 'PRON', 'ADJ', 'ADP', 'VERB']: # 前置詞ひろう\n",
    "            if token.head.dep_ == 'ROOT':\n",
    "                pregroup_types[token.text] = n\n",
    "                dependencies.append((token.text, token.head.text))\n",
    "            elif token.dep_ == 'conj': # 並列に対応させる\n",
    "                if token.head.head.dep_ == 'ROOT': # 無理矢理２つまで対応\n",
    "                    pregroup_types[token.text] = n\n",
    "                    dependencies.append((token.text, token.head.head.text)) # ROOTとつなげる\n",
    "            elif token.dep_ == 'pobj': # 前置詞がついた目的後拾う\n",
    "                if token.head.head.dep_ == 'ROOT':\n",
    "                    pregroup_types[token.text] = n\n",
    "                    dependencies.append((token.text, token.head.text))\n",
    "            elif token.dep_ == 'dobj':\n",
    "                if token.head.head.dep_ == 'ROOT':\n",
    "                    pregroup_types[token.text] = n\n",
    "                    dependencies.append((token.text, token.head.text))\n",
    "\n",
    "    # dep関係による型の割り当て（dep関係リストに基づき、dep相手との語順で場合分け）\n",
    "    for token in doc:\n",
    "        for dep in dependencies:\n",
    "            if token.text == dep[1]:\n",
    "                idx1 = tokens.index(dep[0])\n",
    "                idx2 = tokens.index(dep[1])\n",
    "                if pregroup_types[dep[0]] == n:\n",
    "                    if idx1 < idx2:\n",
    "                        pregroup_types[token.text] = n.r @ pregroup_types[token.text]\n",
    "                    else:\n",
    "                        pregroup_types[token.text] = pregroup_types[token.text] @ n.l\n",
    "    \n",
    "    return pregroup_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ee9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagram作成\n",
    "def create_diagram(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    pregroup_types = assign_types(doc)\n",
    "\n",
    "    words = []\n",
    "    types = Ty()\n",
    "\n",
    "    # 初めの形を作る\n",
    "    for word, type in pregroup_types.items():\n",
    "        words.append(Word(word, type))\n",
    "\n",
    "    diagram = Id().tensor(*words)\n",
    "\n",
    "    for type in pregroup_types.values():\n",
    "        types @= type\n",
    "    \n",
    "    # cupsの適用\n",
    "    i = 0\n",
    "    while i < len(types) - 1:\n",
    "        if types[i:i + 2] == n @ n.r:  \n",
    "            diagram = diagram >> types[:i] @ Cup(n, n.r) @ types[i + 2:]\n",
    "            types = types[:i] @ types[i + 2:]\n",
    "            i = max(0, i - 1)\n",
    "        elif types[i:i + 2] == n.l @ n:\n",
    "            diagram = diagram >> types[:i] @ Cup(n.l, n) @ types[i + 2:]\n",
    "            types = types[:i] @ types[i + 2:]\n",
    "            i = max(0, i - 1)\n",
    "        elif types[i:i + 2] == s @ s.r:\n",
    "            diagram = diagram >> types[:i] @ Cup(s, s.r) @ types[i + 2:]\n",
    "            types = types[:i] @ types[i + 2:]\n",
    "            i = max(0, i - 1)\n",
    "        elif types[i:i + 2] == s.l @ s:\n",
    "            diagram = diagram >> types[:i] @ Cup(s.l, s) @ types[i + 2:]\n",
    "            types = types[:i] @ types[i + 2:]\n",
    "            i = max(0, i - 1)\n",
    "        else:\n",
    "            i += 1\n",
    "            \n",
    "    return diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f62b41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, stratify=df['label'], test_size=0.2, random_state=0)\n",
    "train_sentences = train_df['text']\n",
    "test_sentences = test_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2b1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ひとつめ\n",
    "train_y = train_df['flight']\n",
    "test_y = test_df['flight']\n",
    "\n",
    "# ラベルのone-hot表現\n",
    "train_labels = np.array([[1, 0] if i == 1 else [0, 1] for i in train_y])\n",
    "test_labels = np.array([[1, 0] if i == 1 else [0, 1] for i in test_y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de3c96a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各データセットのdiagram化\n",
    "train_diagrams = []\n",
    "test_diagrams = []\n",
    "\n",
    "for sentence in train_sentences:\n",
    "    train_diagrams.append(create_diagram(sentence))\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    test_diagrams.append(create_diagram(sentence))\n",
    "\n",
    "# チェック用\n",
    "#for d in range(len(train_sentences)):\n",
    "    #draw(train_diagrams[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7b258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 量子回路設計\n",
    "ansatz = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1}, n_layers=1, n_single_qubit_params=3)\n",
    "\n",
    "train_circuits = [ansatz(diagram) for diagram in train_diagrams]\n",
    "test_circuits = [ansatz(diagram) for diagram in test_diagrams]\n",
    "\n",
    "# チェック用\n",
    "# train_circuits[0].draw(figsize=(4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd87e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_circuits = train_circuits + test_circuits # モデル初期化時に全量子回路を提供するための準備\n",
    "model = NumpyModel.from_diagrams(all_circuits, use_jit=True)\n",
    "\n",
    "# 損失関数と予測精度の定義\n",
    "bce = BinaryCrossEntropyLoss(use_jax=True)\n",
    "acc = lambda y_hat, y: np.mean(np.argmax(y_hat, axis=1) == np.argmax(y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6575c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 30\n",
    "# LEARNING_RATE = 3e-2\n",
    "EPOCHS = 400\n",
    "SEED = 0\n",
    "\n",
    "# trainerの定義\n",
    "trainer = QuantumTrainer(\n",
    "    model,\n",
    "    loss_function=bce,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'a': 0.1, 'c': 0.06, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions={'acc': acc},\n",
    "    evaluate_on_train=True,\n",
    "    verbose='text',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "train_dataset = Dataset(train_circuits, train_labels, batch_size=BATCH_SIZE)\n",
    "test_dataset = Dataset(test_circuits, test_labels, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9a8a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100:  train/loss: 0.8884   valid/loss: 0.7424   train/time: 2.57s   valid/time: 0.28s   train/acc: 0.8594   valid/acc: 0.7500\n",
      "Epoch 200:  train/loss: 0.3420   valid/loss: 0.7326   train/time: 2.52s   valid/time: 0.27s   train/acc: 0.8594   valid/acc: 0.6250\n",
      "Epoch 300:  train/loss: 0.2041   valid/loss: 0.7299   train/time: 2.49s   valid/time: 0.27s   train/acc: 0.9219   valid/acc: 0.6250\n",
      "Epoch 400:  train/loss: 0.2395   valid/loss: 0.7655   train/time: 2.50s   valid/time: 0.27s   train/acc: 0.9531   valid/acc: 0.6250\n",
      "\n",
      "Training completed!\n",
      "train/time: 10.07s   train/time_per_epoch: 0.03s   train/time_per_step: 0.01s   valid/time: 1.10s   valid/time_per_eval: 0.00s\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(train_dataset, test_dataset, log_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "828d2b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([6.2663120e-01, 5.1853932e-02, 2.4291335e-01, 2.9507074e-01,\n",
       "       9.2937756e-01, 6.9530469e-01, 1.7896788e-01, 2.6176491e-01,\n",
       "       5.5618834e-02, 4.1168304e-03, 9.2141396e-01, 1.3006808e-02,\n",
       "       8.5464347e-04, 1.5265293e-01, 1.9680899e-01, 3.0761484e-02],      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive判定確率\n",
    "y_hat = model.forward(test_circuits) # one-hotで確率を表示\n",
    "prob_class_0 = y_hat[:, 0]  # positiveクラスの確率\n",
    "prob_class_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1405a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100:  train/loss: 0.5858   valid/loss: 0.9882   train/time: 9.72s   valid/time: 1.53s   train/acc: 0.8438   valid/acc: 0.5625\n",
      "Epoch 200:  train/loss: 0.4203   valid/loss: 1.0129   train/time: 2.88s   valid/time: 0.31s   train/acc: 0.9375   valid/acc: 0.5625\n",
      "Epoch 300:  train/loss: 0.5864   valid/loss: 0.9782   train/time: 2.52s   valid/time: 0.28s   train/acc: 0.9531   valid/acc: 0.5625\n",
      "Epoch 400:  train/loss: 0.1531   valid/loss: 0.9570   train/time: 2.68s   valid/time: 0.29s   train/acc: 0.9844   valid/acc: 0.5625\n",
      "\n",
      "Training completed!\n",
      "train/time: 17.80s   train/time_per_epoch: 0.04s   train/time_per_step: 0.01s   valid/time: 2.42s   valid/time_per_eval: 0.01s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([0.95553625, 0.02032341, 0.24291335, 0.05779175, 0.9254728 ,\n",
       "       0.819933  , 0.55946594, 0.7720055 , 0.60184073, 0.654766  ,\n",
       "       0.5435744 , 0.12189666, 0.88023776, 0.7604412 , 0.14741237,\n",
       "       0.02161395], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ふたつめ\n",
    "train_y = train_df['hotel']\n",
    "test_y = test_df['hotel']\n",
    "\n",
    "train_labels = np.array([[1, 0] if i == 1 else [0, 1] for i in train_y])\n",
    "test_labels = np.array([[1, 0] if i == 1 else [0, 1] for i in test_y])\n",
    "\n",
    "train_diagrams = []\n",
    "test_diagrams = []\n",
    "\n",
    "for sentence in train_sentences:\n",
    "    train_diagrams.append(create_diagram(sentence))\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    test_diagrams.append(create_diagram(sentence))\n",
    "\n",
    "ansatz = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1}, n_layers=1, n_single_qubit_params=3)\n",
    "\n",
    "train_circuits = [ansatz(diagram) for diagram in train_diagrams]\n",
    "test_circuits = [ansatz(diagram) for diagram in test_diagrams]\n",
    "\n",
    "all_circuits = train_circuits + test_circuits # モデル初期化時に全量子回路を提供するための準備\n",
    "model = NumpyModel.from_diagrams(all_circuits, use_jit=True)\n",
    "\n",
    "# 損失関数と予測精度の定義\n",
    "bce = BinaryCrossEntropyLoss(use_jax=True)\n",
    "acc = lambda y_hat, y: np.mean(np.argmax(y_hat, axis=1) == np.argmax(y, axis=1))\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "# LEARNING_RATE = 3e-2\n",
    "EPOCHS = 400\n",
    "SEED = 0\n",
    "\n",
    "# trainerの定義\n",
    "trainer = QuantumTrainer(\n",
    "    model,\n",
    "    loss_function=bce,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'a': 0.1, 'c': 0.06, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions={'acc': acc},\n",
    "    evaluate_on_train=True,\n",
    "    verbose='text',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "train_dataset = Dataset(train_circuits, train_labels, batch_size=BATCH_SIZE)\n",
    "test_dataset = Dataset(test_circuits, test_labels, shuffle=False)\n",
    "\n",
    "trainer.fit(train_dataset, test_dataset, log_interval=100)\n",
    "\n",
    "y_hat = model.forward(test_circuits)\n",
    "prob_class_1 = y_hat[:, 0]\n",
    "prob_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3987cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100:  train/loss: 0.3571   valid/loss: 2.7034   train/time: 10.21s   valid/time: 1.82s   train/acc: 0.8438   valid/acc: 0.2500\n",
      "\n",
      "Training completed!\n",
      "train/time: 10.21s   train/time_per_epoch: 0.10s   train/time_per_step: 0.03s   valid/time: 1.82s   valid/time_per_eval: 0.02s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([8.8579011e-01, 9.5026559e-01, 2.4291335e-01, 7.8096002e-01,\n",
       "       1.3874125e-03, 9.8753023e-01, 1.9198383e-01, 5.4476327e-01,\n",
       "       3.9679068e-01, 5.8757165e-04, 9.1705936e-01, 1.3945549e-03,\n",
       "       1.6872494e-03, 1.2383179e-01, 3.2809169e-03, 6.5965044e-01],      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# みっつめ\n",
    "train_y = train_df['restaurant']\n",
    "test_y = test_df['restaurant']\n",
    "\n",
    "train_labels = np.array([[1, 0] if i == 1 else [0, 1] for i in train_y])\n",
    "test_labels = np.array([[1, 0] if i == 1 else [0, 1] for i in test_y])\n",
    "\n",
    "train_diagrams = []\n",
    "test_diagrams = []\n",
    "\n",
    "for sentence in train_sentences:\n",
    "    train_diagrams.append(create_diagram(sentence))\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    test_diagrams.append(create_diagram(sentence))\n",
    "\n",
    "ansatz = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1}, n_layers=1, n_single_qubit_params=3)\n",
    "\n",
    "train_circuits = [ansatz(diagram) for diagram in train_diagrams]\n",
    "test_circuits = [ansatz(diagram) for diagram in test_diagrams]\n",
    "\n",
    "all_circuits = train_circuits + test_circuits # モデル初期化時に全量子回路を提供するための準備\n",
    "model = NumpyModel.from_diagrams(all_circuits, use_jit=True)\n",
    "\n",
    "# 損失関数と予測精度の定義\n",
    "bce = BinaryCrossEntropyLoss(use_jax=True)\n",
    "acc = lambda y_hat, y: np.mean(np.argmax(y_hat, axis=1) == np.argmax(y, axis=1))\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "# LEARNING_RATE = 3e-2\n",
    "EPOCHS = 100\n",
    "SEED = 0\n",
    "\n",
    "# trainerの定義\n",
    "trainer = QuantumTrainer(\n",
    "    model,\n",
    "    loss_function=bce,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'a': 0.1, 'c': 0.06, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions={'acc': acc},\n",
    "    evaluate_on_train=True,\n",
    "    verbose='text',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "train_dataset = Dataset(train_circuits, train_labels, batch_size=BATCH_SIZE)\n",
    "test_dataset = Dataset(test_circuits, test_labels, shuffle=False)\n",
    "\n",
    "trainer.fit(train_dataset, test_dataset, log_interval=100)\n",
    "\n",
    "y_hat = model.forward(test_circuits) \n",
    "prob_class_2 = y_hat[:, 0]  # positiveクラスの確率\n",
    "prob_class_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29cc9f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0 2 0 2 1 1 1 1 0 1 1 1 0 2]\n",
      "[1 1 0 0 2 0 2 0 1 1 0 2 2 1 2 0]\n",
      "Accuracy: 0.375\n"
     ]
    }
   ],
   "source": [
    "# 予測確率をまとめて [num_samples, 3] に\n",
    "prob_matrix = np.vstack([prob_class_0, prob_class_1, prob_class_2]).T\n",
    "\n",
    "# 各行で最大の確率のインデックス（クラス番号）を取得\n",
    "pred_labels = np.argmax(prob_matrix, axis=1)\n",
    "\n",
    "true_labels = test_df['label'].values\n",
    "print(pred_labels)\n",
    "print(true_labels)\n",
    "\n",
    "# 正解率\n",
    "accuracy = np.mean(pred_labels == true_labels)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41c8774b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 文: Are pets allowed on the train?\n",
      " 予測ラベル: 2\n",
      " 正解ラベル: 1\n",
      " 文: Do you serve breakfast here?\n",
      " 予測ラベル: 2\n",
      " 正解ラベル: 0\n",
      " 文: Is Wi-Fi free?\n",
      " 予測ラベル: 0\n",
      " 正解ラベル: 2\n",
      " 文: Where can I buy snacks?\n",
      " 予測ラベル: 2\n",
      " 正解ラベル: 0\n",
      " 文: Is there room service?\n",
      " 予測ラベル: 1\n",
      " 正解ラベル: 2\n",
      " 文: I would like to order a pizza.\n",
      " 予測ラベル: 1\n",
      " 正解ラベル: 0\n",
      " 文: I need an extra towel.\n",
      " 予測ラベル: 1\n",
      " 正解ラベル: 2\n",
      " 文: Where’s the front desk?\n",
      " 予測ラベル: 1\n",
      " 正解ラベル: 2\n",
      " 文: Is breakfast included?\n",
      " 予測ラベル: 0\n",
      " 正解ラベル: 2\n",
      " 文: Is there a good sushi place nearby?\n",
      " 予測ラベル: 2\n",
      " 正解ラベル: 0\n"
     ]
    }
   ],
   "source": [
    "for idx, (sentence, true, pred) in enumerate(zip(test_sentences, true_labels, pred_labels)):\n",
    "    if pred != true:\n",
    "        #print(f\"【誤分類】\")\n",
    "        print(f\" 文: {sentence}\")\n",
    "        print(f\" 予測ラベル: {pred}\")\n",
    "        print(f\" 正解ラベル: {true}\")\n",
    "        #print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
